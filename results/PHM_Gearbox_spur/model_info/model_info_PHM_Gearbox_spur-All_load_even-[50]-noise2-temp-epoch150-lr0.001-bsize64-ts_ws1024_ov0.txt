Experiment Name: PHM_Gearbox_spur-All_load_even-[50]-noise2-temp-epoch150-lr0.001-bsize64-ts_ws1024_ov0
Model Architecture: ImprovedProjDilResTransformer2
Total Parameters: 92,264
Trainable Parameters: 92,264
Model Size: 0.36 MB

Model Structure:
ImprovedProjDilResTransformer2(
  (proj_conv): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
  (conv1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (dil_conv1): MultiDilatedConv(
    (dilated_convs): ModuleList(
      (0): Conv1d(32, 5, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
      (1): Conv1d(32, 5, kernel_size=(5,), stride=(1,), padding=(6,), dilation=(3,), bias=False)
      (2): Conv1d(32, 5, kernel_size=(5,), stride=(1,), padding=(10,), dilation=(5,), bias=False)
      (3): Conv1d(32, 5, kernel_size=(5,), stride=(1,), padding=(14,), dilation=(7,), bias=False)
      (4): Conv1d(32, 5, kernel_size=(5,), stride=(1,), padding=(18,), dilation=(9,), bias=False)
      (5): Conv1d(32, 5, kernel_size=(5,), stride=(1,), padding=(22,), dilation=(11,), bias=False)
    )
    (final_conv): Conv1d(30, 32, kernel_size=(1,), stride=(1,), bias=False)
  )
  (dil_bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dil_conv2): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))
  (down_sample): Sequential(
    (0): Conv1d(32, 32, kernel_size=(1,), stride=(2,))
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (res_block1): ImprovedDilResidualBlock(
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv1): MultiDilatedConv(
      (dilated_convs): ModuleList(
        (0): Conv1d(32, 10, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): Conv1d(32, 10, kernel_size=(5,), stride=(1,), padding=(6,), dilation=(3,), bias=False)
        (2): Conv1d(32, 10, kernel_size=(5,), stride=(1,), padding=(10,), dilation=(5,), bias=False)
        (3): Conv1d(32, 10, kernel_size=(5,), stride=(1,), padding=(14,), dilation=(7,), bias=False)
        (4): Conv1d(32, 10, kernel_size=(5,), stride=(1,), padding=(18,), dilation=(9,), bias=False)
        (5): Conv1d(32, 10, kernel_size=(5,), stride=(1,), padding=(22,), dilation=(11,), bias=False)
      )
      (final_conv): Conv1d(60, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (attention): CompactMultiHeadAttention(
      (to_reduced): Conv1d(64, 48, kernel_size=(1,), stride=(1,), bias=False)
      (to_out): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))
    (shortcut): Sequential(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,))
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (res_block2): ImprovedDilResidualBlock(
    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv1): MultiDilatedConv(
      (dilated_convs): ModuleList(
        (0): Conv1d(64, 10, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): Conv1d(64, 10, kernel_size=(5,), stride=(1,), padding=(6,), dilation=(3,), bias=False)
        (2): Conv1d(64, 10, kernel_size=(5,), stride=(1,), padding=(10,), dilation=(5,), bias=False)
        (3): Conv1d(64, 10, kernel_size=(5,), stride=(1,), padding=(14,), dilation=(7,), bias=False)
        (4): Conv1d(64, 10, kernel_size=(5,), stride=(1,), padding=(18,), dilation=(9,), bias=False)
        (5): Conv1d(64, 10, kernel_size=(5,), stride=(1,), padding=(22,), dilation=(11,), bias=False)
      )
      (final_conv): Conv1d(60, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (attention): CompactMultiHeadAttention(
      (to_reduced): Conv1d(64, 48, kernel_size=(1,), stride=(1,), bias=False)
      (to_out): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))
    (shortcut): Sequential(
      (0): Conv1d(64, 64, kernel_size=(1,), stride=(2,))
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool1d(output_size=1)
  (classifier): Linear(in_features=64, out_features=8, bias=True)
)